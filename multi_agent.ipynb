{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 101: Building Multi-Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to walk through setting up a **multi-agent workflow** in LangGraph. We will start from a simple ReAct agent and add additional steps into the workflow, simulating a realistic customer support example, showcasing human-in-the-loop, long term memory, and the LangGraph pre-built library. \n",
    "\n",
    "The agent utilizes the [Chinook database](https://www.sqlitetutorial.net/sqlite-sample-database/), and is able to handle customer inqueries related to invoice and music. \n",
    "\n",
    "![Arch](../images/architecture.png) \n",
    "\n",
    "\n",
    "\n",
    "For a deeper dive into LangGraph primitives and learning our framework, check out our [LangChain Academy](https://academy.langchain.com/courses/intro-to-langgraph)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-work: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's load our environment variables from our .env file. Make sure all of the keys necessary in .env.example are included!\n",
    "We use OpenAI in this example, but feel free to swap ChatOpenAI with other model providers that you prefer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Note: If you are using another `ChatModel`, you can define it in `models.py` and import it here\n",
    "# from models import AZURE_OPENAI_GPT_4O\n",
    "# llm = AZURE_OPENAI_GPT_4O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading sample customer data\n",
    "\n",
    "The agent utilizes the [Chinook database](https://www.sqlitetutorial.net/sqlite-sample-database/), which contains sample information on customer information, purchase history, and music catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    connection.executescript(sql_script)\n",
    "    return create_engine(\n",
    "        \"sqlite://\",\n",
    "        creator=lambda: connection,\n",
    "        poolclass=StaticPool,\n",
    "        connect_args={\"check_same_thread\": False},\n",
    "    )\n",
    "\n",
    "engine = get_engine_for_chinook_db()\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Album',), ('Artist',), ('Customer',), ('Employee',), ('Genre',), ('Invoice',), ('InvoiceLine',), ('MediaType',), ('Playlist',), ('PlaylistTrack',), ('Track',)]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "## all tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Luís', 'Gonçalves', 'Embraer - Empresa Brasileira de Aeronáutica S.A.', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', '+55 (12) 3923-5555', '+55 (12) 3923-5566', 'luisg@embraer.com.br', 3)\n",
      "(2, 'Leonie', 'Köhler', None, 'Theodor-Heuss-Straße 34', 'Stuttgart', None, 'Germany', '70174', '+49 0711 2842222', None, 'leonekohler@surfeu.de', 5)\n",
      "(3, 'François', 'Tremblay', None, '1498 rue Bélanger', 'Montréal', 'QC', 'Canada', 'H2G 1A7', '+1 (514) 721-4711', None, 'ftremblay@gmail.com', 3)\n",
      "(4, 'Bjørn', 'Hansen', None, 'Ullevålsveien 14', 'Oslo', None, 'Norway', '0171', '+47 22 44 22 22', None, 'bjorn.hansen@yahoo.no', 4)\n",
      "(5, 'František', 'Wichterlová', 'JetBrains s.r.o.', 'Klanova 9/506', 'Prague', None, 'Czech Republic', '14700', '+420 2 4172 5555', '+420 2 4172 5555', 'frantisekw@jetbrains.com', 4)\n",
      "(6, 'Helena', 'Holý', None, 'Rilská 3174/6', 'Prague', None, 'Czech Republic', '14300', '+420 2 4177 0449', None, 'hholy@gmail.com', 5)\n",
      "(7, 'Astrid', 'Gruber', None, 'Rotenturmstraße 4, 1010 Innere Stadt', 'Vienne', None, 'Austria', '1010', '+43 01 5134505', None, 'astrid.gruber@apple.at', 5)\n",
      "(8, 'Daan', 'Peeters', None, 'Grétrystraat 63', 'Brussels', None, 'Belgium', '1000', '+32 02 219 03 03', None, 'daan_peeters@apple.be', 4)\n",
      "(9, 'Kara', 'Nielsen', None, 'Sønder Boulevard 51', 'Copenhagen', None, 'Denmark', '1720', '+453 3331 9991', None, 'kara.nielsen@jubii.dk', 4)\n",
      "(10, 'Eduardo', 'Martins', 'Woodstock Discos', 'Rua Dr. Falcão Filho, 155', 'São Paulo', 'SP', 'Brazil', '01007-010', '+55 (11) 3033-5446', '+55 (11) 3033-4564', 'eduardo@woodstock.com.br', 4)\n",
      "(11, 'Alexandre', 'Rocha', 'Banco do Brasil S.A.', 'Av. Paulista, 2022', 'São Paulo', 'SP', 'Brazil', '01310-200', '+55 (11) 3055-3278', '+55 (11) 3055-8131', 'alero@uol.com.br', 5)\n",
      "(12, 'Roberto', 'Almeida', 'Riotur', 'Praça Pio X, 119', 'Rio de Janeiro', 'RJ', 'Brazil', '20040-020', '+55 (21) 2271-7000', '+55 (21) 2271-7070', 'roberto.almeida@riotur.gov.br', 3)\n",
      "(13, 'Fernanda', 'Ramos', None, 'Qe 7 Bloco G', 'Brasília', 'DF', 'Brazil', '71020-677', '+55 (61) 3363-5547', '+55 (61) 3363-7855', 'fernadaramos4@uol.com.br', 4)\n",
      "(14, 'Mark', 'Philips', 'Telus', '8210 111 ST NW', 'Edmonton', 'AB', 'Canada', 'T6G 2C7', '+1 (780) 434-4554', '+1 (780) 434-5565', 'mphilips12@shaw.ca', 5)\n",
      "(15, 'Jennifer', 'Peterson', 'Rogers Canada', '700 W Pender Street', 'Vancouver', 'BC', 'Canada', 'V6C 1G8', '+1 (604) 688-2255', '+1 (604) 688-8756', 'jenniferp@rogers.ca', 3)\n",
      "(16, 'Frank', 'Harris', 'Google Inc.', '1600 Amphitheatre Parkway', 'Mountain View', 'CA', 'USA', '94043-1351', '+1 (650) 253-0000', '+1 (650) 253-0000', 'fharris@google.com', 4)\n",
      "(17, 'Jack', 'Smith', 'Microsoft Corporation', '1 Microsoft Way', 'Redmond', 'WA', 'USA', '98052-8300', '+1 (425) 882-8080', '+1 (425) 882-8081', 'jacksmith@microsoft.com', 5)\n",
      "(18, 'Michelle', 'Brooks', None, '627 Broadway', 'New York', 'NY', 'USA', '10012-2612', '+1 (212) 221-3546', '+1 (212) 221-4679', 'michelleb@aol.com', 3)\n",
      "(19, 'Tim', 'Goyer', 'Apple Inc.', '1 Infinite Loop', 'Cupertino', 'CA', 'USA', '95014', '+1 (408) 996-1010', '+1 (408) 996-1011', 'tgoyer@apple.com', 3)\n",
      "(20, 'Dan', 'Miller', None, '541 Del Medio Avenue', 'Mountain View', 'CA', 'USA', '94040-111', '+1 (650) 644-3358', None, 'dmiller@comcast.com', 4)\n",
      "(21, 'Kathy', 'Chase', None, '801 W 4th Street', 'Reno', 'NV', 'USA', '89503', '+1 (775) 223-7665', None, 'kachase@hotmail.com', 5)\n",
      "(22, 'Heather', 'Leacock', None, '120 S Orange Ave', 'Orlando', 'FL', 'USA', '32801', '+1 (407) 999-7788', None, 'hleacock@gmail.com', 4)\n",
      "(23, 'John', 'Gordon', None, '69 Salem Street', 'Boston', 'MA', 'USA', '2113', '+1 (617) 522-1333', None, 'johngordon22@yahoo.com', 4)\n",
      "(24, 'Frank', 'Ralston', None, '162 E Superior Street', 'Chicago', 'IL', 'USA', '60611', '+1 (312) 332-3232', None, 'fralston@gmail.com', 3)\n",
      "(25, 'Victor', 'Stevens', None, '319 N. Frances Street', 'Madison', 'WI', 'USA', '53703', '+1 (608) 257-0597', None, 'vstevens@yahoo.com', 5)\n",
      "(26, 'Richard', 'Cunningham', None, '2211 W Berry Street', 'Fort Worth', 'TX', 'USA', '76110', '+1 (817) 924-7272', None, 'ricunningham@hotmail.com', 4)\n",
      "(27, 'Patrick', 'Gray', None, '1033 N Park Ave', 'Tucson', 'AZ', 'USA', '85719', '+1 (520) 622-4200', None, 'patrick.gray@aol.com', 4)\n",
      "(28, 'Julia', 'Barnett', None, '302 S 700 E', 'Salt Lake City', 'UT', 'USA', '84102', '+1 (801) 531-7272', None, 'jubarnett@gmail.com', 5)\n",
      "(29, 'Robert', 'Brown', None, '796 Dundas Street West', 'Toronto', 'ON', 'Canada', 'M6J 1V1', '+1 (416) 363-8888', None, 'robbrown@shaw.ca', 3)\n",
      "(30, 'Edward', 'Francis', None, '230 Elgin Street', 'Ottawa', 'ON', 'Canada', 'K2P 1L7', '+1 (613) 234-3322', None, 'edfrancis@yachoo.ca', 3)\n",
      "(31, 'Martha', 'Silk', None, '194A Chain Lake Drive', 'Halifax', 'NS', 'Canada', 'B3S 1C5', '+1 (902) 450-0450', None, 'marthasilk@gmail.com', 5)\n",
      "(32, 'Aaron', 'Mitchell', None, '696 Osborne Street', 'Winnipeg', 'MB', 'Canada', 'R3L 2B9', '+1 (204) 452-6452', None, 'aaronmitchell@yahoo.ca', 4)\n",
      "(33, 'Ellie', 'Sullivan', None, '5112 48 Street', 'Yellowknife', 'NT', 'Canada', 'X1A 1N6', '+1 (867) 920-2233', None, 'ellie.sullivan@shaw.ca', 3)\n",
      "(34, 'João', 'Fernandes', None, 'Rua da Assunção 53', 'Lisbon', None, 'Portugal', None, '+351 (213) 466-111', None, 'jfernandes@yahoo.pt', 4)\n",
      "(35, 'Madalena', 'Sampaio', None, 'Rua dos Campeões Europeus de Viena, 4350', 'Porto', None, 'Portugal', None, '+351 (225) 022-448', None, 'masampaio@sapo.pt', 4)\n",
      "(36, 'Hannah', 'Schneider', None, 'Tauentzienstraße 8', 'Berlin', None, 'Germany', '10789', '+49 030 26550280', None, 'hannah.schneider@yahoo.de', 5)\n",
      "(37, 'Fynn', 'Zimmermann', None, 'Berger Straße 10', 'Frankfurt', None, 'Germany', '60316', '+49 069 40598889', None, 'fzimmermann@yahoo.de', 3)\n",
      "(38, 'Niklas', 'Schröder', None, 'Barbarossastraße 19', 'Berlin', None, 'Germany', '10779', '+49 030 2141444', None, 'nschroder@surfeu.de', 3)\n",
      "(39, 'Camille', 'Bernard', None, '4, Rue Milton', 'Paris', None, 'France', '75009', '+33 01 49 70 65 65', None, 'camille.bernard@yahoo.fr', 4)\n",
      "(40, 'Dominique', 'Lefebvre', None, '8, Rue Hanovre', 'Paris', None, 'France', '75002', '+33 01 47 42 71 71', None, 'dominiquelefebvre@gmail.com', 4)\n",
      "(41, 'Marc', 'Dubois', None, '11, Place Bellecour', 'Lyon', None, 'France', '69002', '+33 04 78 30 30 30', None, 'marc.dubois@hotmail.com', 5)\n",
      "(42, 'Wyatt', 'Girard', None, '9, Place Louis Barthou', 'Bordeaux', None, 'France', '33000', '+33 05 56 96 96 96', None, 'wyatt.girard@yahoo.fr', 3)\n",
      "(43, 'Isabelle', 'Mercier', None, '68, Rue Jouvence', 'Dijon', None, 'France', '21000', '+33 03 80 73 66 99', None, 'isabelle_mercier@apple.fr', 3)\n",
      "(44, 'Terhi', 'Hämäläinen', None, 'Porthaninkatu 9', 'Helsinki', None, 'Finland', '00530', '+358 09 870 2000', None, 'terhi.hamalainen@apple.fi', 3)\n",
      "(45, 'Ladislav', 'Kovács', None, 'Erzsébet krt. 58.', 'Budapest', None, 'Hungary', 'H-1073', None, None, 'ladislav_kovacs@apple.hu', 3)\n",
      "(46, 'Hugh', \"O'Reilly\", None, '3 Chatham Street', 'Dublin', 'Dublin', 'Ireland', None, '+353 01 6792424', None, 'hughoreilly@apple.ie', 3)\n",
      "(47, 'Lucas', 'Mancini', None, 'Via Degli Scipioni, 43', 'Rome', 'RM', 'Italy', '00192', '+39 06 39733434', None, 'lucas.mancini@yahoo.it', 5)\n",
      "(48, 'Johannes', 'Van der Berg', None, 'Lijnbaansgracht 120bg', 'Amsterdam', 'VV', 'Netherlands', '1016', '+31 020 6223130', None, 'johavanderberg@yahoo.nl', 5)\n",
      "(49, 'Stanisław', 'Wójcik', None, 'Ordynacka 10', 'Warsaw', None, 'Poland', '00-358', '+48 22 828 37 39', None, 'stanisław.wójcik@wp.pl', 4)\n",
      "(50, 'Enrique', 'Muñoz', None, 'C/ San Bernardo 85', 'Madrid', None, 'Spain', '28015', '+34 914 454 454', None, 'enrique_munoz@yahoo.es', 5)\n",
      "(51, 'Joakim', 'Johansson', None, 'Celsiusg. 9', 'Stockholm', None, 'Sweden', '11230', '+46 08-651 52 52', None, 'joakim.johansson@yahoo.se', 5)\n",
      "(52, 'Emma', 'Jones', None, '202 Hoxton Street', 'London', None, 'United Kingdom', 'N1 5LH', '+44 020 7707 0707', None, 'emma_jones@hotmail.com', 3)\n",
      "(53, 'Phil', 'Hughes', None, '113 Lupus St', 'London', None, 'United Kingdom', 'SW1V 3EN', '+44 020 7976 5722', None, 'phil.hughes@gmail.com', 3)\n",
      "(54, 'Steve', 'Murray', None, '110 Raeburn Pl', 'Edinburgh ', None, 'United Kingdom', 'EH4 1HH', '+44 0131 315 3300', None, 'steve.murray@yahoo.uk', 5)\n",
      "(55, 'Mark', 'Taylor', None, '421 Bourke Street', 'Sidney', 'NSW', 'Australia', '2010', '+61 (02) 9332 3633', None, 'mark.taylor@yahoo.au', 4)\n",
      "(56, 'Diego', 'Gutiérrez', None, '307 Macacha Güemes', 'Buenos Aires', None, 'Argentina', '1106', '+54 (0)11 4311 4333', None, 'diego.gutierrez@yahoo.ar', 4)\n",
      "(57, 'Luis', 'Rojas', None, 'Calle Lira, 198', 'Santiago', None, 'Chile', None, '+56 (0)2 635 4444', None, 'luisrojas@yahoo.cl', 5)\n",
      "(58, 'Manoj', 'Pareek', None, '12,Community Centre', 'Delhi', None, 'India', '110017', '+91 0124 39883988', None, 'manoj.pareek@rediff.com', 3)\n",
      "(59, 'Puja', 'Srivastava', None, '3,Raj Bhavan Road', 'Bangalore', None, 'India', '560001', '+91 080 22289999', None, 'puja_srivastava@yahoo.in', 3)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "res=db.run(\"SELECT * FROM Customer\")\n",
    "res=ast.literal_eval(res)\n",
    "for i in res:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up short-term and long-term memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also initialize a checkpointer for **short-term memory**, maintaining context within a single thread. \n",
    "\n",
    "**Long term memory** lets you store and recall information between conversations. Today, we will utilize our long term memory store to store user preferences for personalization. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initializing long term memory store \n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Initializing checkpoint for thread-level memory \n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building ReAct Sub-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Building a ReAct Agent from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are set up, we are ready to build out our **first subagent**. This is a simple ReAct agent that fetches information related to music store catalog, utilizing a set of tools to generate its response. \n",
    "\n",
    "![react_1](../images/music_subagent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does information flow through the steps?  \n",
    "\n",
    "State is the first LangGraph concept we'll cover. **State can be thought of as the memory of the agent - its a shared data structure that’s passed on between the nodes of your graph**, representing the current snapshot of your application. \n",
    "\n",
    "For this our customer support agent our state will track the following elements: \n",
    "1. The customer ID\n",
    "2. Conversation history\n",
    "3. Memory from long term memory store\n",
    "4. Remaining steps, which tracks # steps until it hits recursion limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class State(TypedDict):\n",
    "    customer_id: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    loaded_memory: str\n",
    "    remaining_steps: RemainingSteps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools\n",
    "Let's define a list of **tools** our agent will have access to. Tools are functionts that can act as extension of the LLM's capabilities. In our case, we will create several tools that interacts with the Chinook database regarding music. \n",
    "\n",
    "We can create tools using the @tool decorator to create a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import ast\n",
    "\n",
    "@tool\n",
    "def get_albums_by_artist(artist: str):\n",
    "    \"\"\"Get albums by an artist.\"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT Album.Title, Artist.Name \n",
    "        FROM Album \n",
    "        JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
    "        WHERE Artist.Name LIKE '%{artist}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def get_tracks_by_artist(artist: str):\n",
    "    \"\"\"Get songs by an artist (or similar artists).\"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT Track.Name as SongName, Artist.Name as ArtistName \n",
    "        FROM Album \n",
    "        LEFT JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
    "        LEFT JOIN Track ON Track.AlbumId = Album.AlbumId \n",
    "        WHERE Artist.Name LIKE '%{artist}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def get_songs_by_genre(genre: str):\n",
    "    \"\"\"\n",
    "    Fetch songs from the database that match a specific genre.\n",
    "    \n",
    "    Args:\n",
    "        genre (str): The genre of the songs to fetch.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of songs that match the specified genre.\n",
    "    \"\"\"\n",
    "    genre_id_query = f\"SELECT GenreId FROM Genre WHERE Name LIKE '%{genre}%'\"\n",
    "    genre_ids = db.run(genre_id_query)\n",
    "    if not genre_ids:\n",
    "        return f\"No songs found for the genre: {genre}\"\n",
    "    genre_ids = ast.literal_eval(genre_ids)\n",
    "    genre_id_list = \", \".join(str(gid[0]) for gid in genre_ids)\n",
    "\n",
    "    songs_query = f\"\"\"\n",
    "        SELECT Track.Name as SongName, Artist.Name as ArtistName\n",
    "        FROM Track\n",
    "        LEFT JOIN Album ON Track.AlbumId = Album.AlbumId\n",
    "        LEFT JOIN Artist ON Album.ArtistId = Artist.ArtistId\n",
    "        WHERE Track.GenreId IN ({genre_id_list})\n",
    "        GROUP BY Artist.Name\n",
    "        LIMIT 8;\n",
    "    \"\"\"\n",
    "    songs = db.run(songs_query, include_columns=True)\n",
    "    if not songs:\n",
    "        return f\"No songs found for the genre: {genre}\"\n",
    "    formatted_songs = ast.literal_eval(songs)\n",
    "    return [\n",
    "        {\"Song\": song[\"SongName\"], \"Artist\": song[\"ArtistName\"]}\n",
    "        for song in formatted_songs\n",
    "    ]\n",
    "\n",
    "@tool\n",
    "def check_for_songs(song_title):\n",
    "    \"\"\"Check if a song exists by its name.\"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM Track WHERE Name LIKE '%{song_title}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )\n",
    "\n",
    "music_tools = [get_albums_by_artist, get_tracks_by_artist, get_songs_by_genre, check_for_songs]\n",
    "llm_with_music_tools = model.bind_tools(music_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of tools, we are ready to build nodes that interact with them. \n",
    "\n",
    "Nodes are just python (or JS/TS!) functions. Nodes take in your graph's State as input, execute some logic, and return a new State. \n",
    "\n",
    "Here, we're just going to set up 2 nodes for our ReAct agent:\n",
    "1. **music_assistant**: Reasoning node that decides which function to invoke \n",
    "2. **music_tools**: Node that contains all the available tools and executes the function\n",
    "\n",
    "LangGraph has a pre-built ToolNode that we can utilize to create a node for our tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "# Node\n",
    "music_tool_node = ToolNode(music_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage, SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Music assistant prompt\n",
    "def generate_music_assistant_prompt(memory: str = \"None\") -> str:\n",
    "    return f\"\"\"\n",
    "    You are a member of the assistant team, your role specifically is to focused on helping customers discover and learn about music in our digital catalog. \n",
    "    If you are unable to find playlists, songs, or albums associated with an artist, it is okay. \n",
    "    Just inform the customer that the catalog does not have any playlists, songs, or albums associated with that artist.\n",
    "    You also have context on any saved user preferences, helping you to tailor your response. \n",
    "    \n",
    "    CORE RESPONSIBILITIES:\n",
    "    - Search and provide accurate information about songs, albums, artists, and playlists\n",
    "    - Offer relevant recommendations based on customer interests\n",
    "    - Handle music-related queries with attention to detail\n",
    "    - Help customers discover new music they might enjoy\n",
    "    - You are routed only when there are questions related to music catalog; ignore other questions. \n",
    "    \n",
    "    SEARCH GUIDELINES:\n",
    "    1. Always perform thorough searches before concluding something is unavailable\n",
    "    2. If exact matches aren't found, try:\n",
    "       - Checking for alternative spellings\n",
    "       - Looking for similar artist names\n",
    "       - Searching by partial matches\n",
    "       - Checking different versions/remixes\n",
    "    3. When providing song lists:\n",
    "       - Include the artist name with each song\n",
    "       - Mention the album when relevant\n",
    "       - Note if it's part of any playlists\n",
    "       - Indicate if there are multiple versions\n",
    "    \n",
    "    Additional context is provided below: \n",
    "\n",
    "    Prior saved user preferences: {memory}\n",
    "    \n",
    "    Message history is also attached.  \n",
    "    \"\"\"\n",
    "\n",
    "# Node \n",
    "def music_assistant(state: State, config: RunnableConfig): \n",
    "\n",
    "    # Fetching long term memory. \n",
    "    memory = \"None\" \n",
    "    if \"loaded_memory\" in state: \n",
    "        memory = state[\"loaded_memory\"]\n",
    "\n",
    "    # Intructions for our agent  \n",
    "    music_assistant_prompt = generate_music_assistant_prompt(memory)\n",
    "\n",
    "    # Invoke the model\n",
    "    response = llm_with_music_tools.invoke([SystemMessage(music_assistant_prompt)] + state[\"messages\"])\n",
    "    \n",
    "    # Update the state\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define a control flow that connects between our defined nodes, and that's where the concept of edges come in.\n",
    "\n",
    "**Edges are connections between nodes. They define the flow of the graph.**\n",
    "* **Normal edges** are deterministic and always go from one node to its defined target\n",
    "* **Conditional edges** are used to dynamically route between nodes, implemented as functions that return the next node to visit based upon some logic. \n",
    "\n",
    "In this case, we want a **conditional edge** from our subagent that determines whether to: \n",
    "- Invoke tools, or,\n",
    "- Route to the end if user query has been finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge that determines whether to continue or not\n",
    "def should_continue(state: State, config: RunnableConfig):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Graph!\n",
    "\n",
    "Now that we've defined our State and Nodes, let's put it all together and construct our react agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from utils import show_graph \n",
    "\n",
    "music_workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes \n",
    "music_workflow.add_node(\"music_assistant\", music_assistant)\n",
    "music_workflow.add_node(\"music_tool_node\", music_tool_node)\n",
    "\n",
    "\n",
    "# Add edges \n",
    "# First, we define the start node. The query will always route to the subagent node first. \n",
    "music_workflow.add_edge(START, \"music_assistant\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "music_workflow.add_conditional_edges(\n",
    "    \"music_assistant\",\n",
    "    # Function representing our conditional edge\n",
    "    should_continue,\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"music_tool_node\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "music_workflow.add_edge(\"music_tool_node\", \"music_assistant\")\n",
    "\n",
    "music_catalog_subagent = music_workflow.compile(name=\"music_catalog_subagent\", checkpointer=checkpointer, store = in_memory_store)\n",
    "show_graph(music_catalog_subagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like the Rolling Stones. What songs do you recommend by them or by other artists that I might like?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_tracks_by_artist (call_snhKNKlA4E0IU8vLAbGl1g2S)\n",
      " Call ID: call_snhKNKlA4E0IU8vLAbGl1g2S\n",
      "  Args:\n",
      "    artist: The Rolling Stones\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_tracks_by_artist\n",
      "\n",
      "[{'SongName': 'Time Is On My Side', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Heart Of Stone', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Play With Fire', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Satisfaction', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'As Tears Go By', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Get Off Of My Cloud', 'ArtistName': 'The Rolling Stones'}, {'SongName': \"Mother's Little Helper\", 'ArtistName': 'The Rolling Stones'}, {'SongName': '19th Nervous Breakdown', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Paint It Black', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Under My Thumb', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Ruby Tuesday', 'ArtistName': 'The Rolling Stones'}, {'SongName': \"Let's Spend The Night Together\", 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Intro', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'You Got Me Rocking', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Gimmie Shelters', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Flip The Switch', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Memory Motel', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Corinna', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Saint Of Me', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Wainting On A Friend', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Sister Morphine', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Live With Me', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Respectable', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Thief In The Night', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'The Last Time', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Out Of Control', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Love Is Strong', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'You Got Me Rocking', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Sparks Will Fly', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'The Worst', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'New Faces', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Moon Is Up', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Out Of Tears', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'I Go Wild', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Brand New Car', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Sweethearts Together', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Suck On The Jugular', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Blinded By Rainbows', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Baby Break It Down', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Thru And Thru', 'ArtistName': 'The Rolling Stones'}, {'SongName': 'Mean Disposition', 'ArtistName': 'The Rolling Stones'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_songs_by_genre (call_lAKwN7akk0xM7cQnPS4r0V3X)\n",
      " Call ID: call_lAKwN7akk0xM7cQnPS4r0V3X\n",
      "  Args:\n",
      "    genre: rock\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_songs_by_genre\n",
      "\n",
      "[{\"Song\": \"For Those About To Rock (We Salute You)\", \"Artist\": \"AC/DC\"}, {\"Song\": \"Balls to the Wall\", \"Artist\": \"Accept\"}, {\"Song\": \"Walk On Water\", \"Artist\": \"Aerosmith\"}, {\"Song\": \"All I Really Want\", \"Artist\": \"Alanis Morissette\"}, {\"Song\": \"We Die Young\", \"Artist\": \"Alice In Chains\"}, {\"Song\": \"Cochise\", \"Artist\": \"Audioslave\"}, {\"Song\": \"Money\", \"Artist\": \"BackBeat\"}, {\"Song\": \"Susie Q\", \"Artist\": \"Creedence Clearwater Revival\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some recommended songs by The Rolling Stones:\n",
      "\n",
      "1. **Time Is On My Side**\n",
      "2. **Heart Of Stone**\n",
      "3. **Play With Fire**\n",
      "4. **(I Can't Get No) Satisfaction**\n",
      "5. **As Tears Go By**\n",
      "6. **Get Off Of My Cloud**\n",
      "7. **Mother's Little Helper**\n",
      "8. **19th Nervous Breakdown**\n",
      "9. **Paint It Black**\n",
      "10. **Under My Thumb**\n",
      "11. **Ruby Tuesday**\n",
      "12. **Let's Spend The Night Together**\n",
      "13. **You Got Me Rocking**\n",
      "14. **Gimme Shelter**\n",
      "15. **Respectable**\n",
      "\n",
      "In addition to The Rolling Stones, here are some rock songs from other artists you might enjoy:\n",
      "\n",
      "1. **For Those About To Rock (We Salute You)** by AC/DC\n",
      "2. **Balls to the Wall** by Accept\n",
      "3. **Walk On Water** by Aerosmith\n",
      "4. **All I Really Want** by Alanis Morissette\n",
      "5. **We Die Young** by Alice In Chains\n",
      "6. **Cochise** by Audioslave\n",
      "7. **Money** by BackBeat\n",
      "8. **Susie Q** by Creedence Clearwater Revival\n",
      "\n",
      "Enjoy exploring these tracks!\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "question = \"I like the Rolling Stones. What songs do you recommend by them or by other artists that I might like?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = music_catalog_subagent.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "   message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Building ReAct Agent using LangGraph Pre-built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph offers pre-built libraries for common architectures, allowing us to quickly create architectures like ReAct or multi-agent architacture. A full list of pre-built libraries can be found here: https://langchain-ai.github.io/langgraph/prebuilt/#available-libraries \n",
    "\n",
    "In the last workflow, we have seen how we can build a ReAct agent from scratch. Now, we will show how we can leverage the LangGraph pre-built libraries to achieve similar results. \n",
    "\n",
    "![react_2](../images/invoice_subagent.png)\n",
    "\n",
    "Our **invoice info subagent** is responsible for all customer queries related to the invoices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining tools and prompt\n",
    "Similarly, let's first define a set of tools and our agent prompt below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool \n",
    "def get_invoices_by_customer_sorted_by_date(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Look up all invoices for a customer using their ID.\n",
    "    The invoices are sorted in descending order by invoice date, which helps when the customer wants to view their most recent/oldest invoice, or if \n",
    "    they want to view invoices within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices for the customer.\n",
    "    \"\"\"\n",
    "    return db.run(f\"SELECT * FROM Invoice WHERE CustomerId = {customer_id} ORDER BY InvoiceDate DESC;\")\n",
    "\n",
    "\n",
    "@tool \n",
    "def get_invoices_sorted_by_unit_price(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Use this tool when the customer wants to know the details of one of their invoices based on the unit price/cost of the invoice.\n",
    "    This tool looks up all invoices for a customer, and sorts the unit price from highest to lowest. In order to find the invoice associated with the customer, \n",
    "    we need to know the customer ID.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices sorted by unit price.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT Invoice.*, InvoiceLine.UnitPrice\n",
    "        FROM Invoice\n",
    "        JOIN InvoiceLine ON Invoice.InvoiceId = InvoiceLine.InvoiceId\n",
    "        WHERE Invoice.CustomerId = {customer_id}\n",
    "        ORDER BY InvoiceLine.UnitPrice DESC;\n",
    "    \"\"\"\n",
    "    return db.run(query)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_employee_by_invoice_and_customer(invoice_id: str, customer_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    This tool will take in an invoice ID and a customer ID and return the employee information associated with the invoice.\n",
    "\n",
    "    Args:\n",
    "        invoice_id (int): The ID of the specific invoice.\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict: Information about the employee associated with the invoice.\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT Employee.FirstName, Employee.Title, Employee.Email\n",
    "        FROM Employee\n",
    "        JOIN Customer ON Customer.SupportRepId = Employee.EmployeeId\n",
    "        JOIN Invoice ON Invoice.CustomerId = Customer.CustomerId\n",
    "        WHERE Invoice.InvoiceId = ({invoice_id}) AND Invoice.CustomerId = ({customer_id});\n",
    "    \"\"\"\n",
    "    \n",
    "    employee_info = db.run(query, include_columns=True)\n",
    "    \n",
    "    if not employee_info:\n",
    "        return f\"No employee found for invoice ID {invoice_id} and customer identifier {customer_id}.\"\n",
    "    return employee_info\n",
    "\n",
    "invoice_tools = [get_invoices_by_customer_sorted_by_date, get_invoices_sorted_by_unit_price, get_employee_by_invoice_and_customer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_subagent_prompt = \"\"\"\n",
    "    You are a subagent among a team of assistants. You are specialized for retrieving and processing invoice information. You are routed for invoice-related portion of the questions, so only respond to them.. \n",
    "\n",
    "    You have access to three tools. These tools enable you to retrieve and process invoice information from the database. Here are the tools:\n",
    "    - get_invoices_by_customer_sorted_by_date: This tool retrieves all invoices for a customer, sorted by invoice date.\n",
    "    - get_invoices_sorted_by_unit_price: This tool retrieves all invoices for a customer, sorted by unit price.\n",
    "    - get_employee_by_invoice_and_customer: This tool retrieves the employee information associated with an invoice and a customer.\n",
    "    \n",
    "    If you are unable to retrieve the invoice information, inform the customer you are unable to retrieve the information, and ask if they would like to search for something else.\n",
    "    \n",
    "    CORE RESPONSIBILITIES:\n",
    "    - Retrieve and process invoice information from the database\n",
    "    - Provide detailed information about invoices, including customer details, invoice dates, total amounts, employees associated with the invoice, etc. when the customer asks for it.\n",
    "    - Always maintain a professional, friendly, and patient demeanor\n",
    "    \n",
    "    You may have additional context that you should use to help answer the customer's query. It will be provided to you below:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the pre-built library\n",
    "Now, let's put them together by using the pre-built ReAct agent library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Define the subagent \n",
    "invoice_information_subagent = create_react_agent(model, tools=invoice_tools, name=\"invoice_information_subagent\",prompt=invoice_subagent_prompt, state_schema=State, checkpointer=checkpointer, store=in_memory_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing!\n",
    "Let's try our new agent out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My customer id is 1. What was my most recent invoice, and who was the employee that helped me with it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: invoice_information_subagent\n",
      "Tool Calls:\n",
      "  get_invoices_by_customer_sorted_by_date (call_16OaYeNsf0OzxE5FERuB6Mdg)\n",
      " Call ID: call_16OaYeNsf0OzxE5FERuB6Mdg\n",
      "  Args:\n",
      "    customer_id: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_invoices_by_customer_sorted_by_date\n",
      "\n",
      "[(382, 1, '2025-08-07 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 8.91), (327, 1, '2024-12-07 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 13.86), (316, 1, '2024-10-27 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 1.98), (195, 1, '2023-05-06 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 0.99), (143, 1, '2022-09-15 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 5.94), (121, 1, '2022-06-13 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 3.96), (98, 1, '2022-03-11 00:00:00', 'Av. Brigadeiro Faria Lima, 2170', 'São José dos Campos', 'SP', 'Brazil', '12227-000', 3.98)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: invoice_information_subagent\n",
      "Tool Calls:\n",
      "  get_employee_by_invoice_and_customer (call_QVfrWufwQPLgml4acLl2GegI)\n",
      " Call ID: call_QVfrWufwQPLgml4acLl2GegI\n",
      "  Args:\n",
      "    invoice_id: 382\n",
      "    customer_id: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_employee_by_invoice_and_customer\n",
      "\n",
      "[{'FirstName': 'Jane', 'Title': 'Sales Support Agent', 'Email': 'jane@chinookcorp.com'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: invoice_information_subagent\n",
      "\n",
      "Your most recent invoice was on **August 7, 2025**, with a total amount of **$8.91**. The employee who assisted you with this invoice was **Jane**, a **Sales Support Agent**. You can reach her at **jane@chinookcorp.com** if you have any follow-up questions.\n"
     ]
    }
   ],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "question = \"My customer id is 1. What was my most recent invoice, and who was the employee that helped me with it?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = invoice_information_subagent.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building multi-agent architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two sub-agents that have different capabilities. How do we make sure customer tasks are appropriately routed between them? \n",
    "\n",
    "This is where the supervisor oversees the workflow, invoking appropriate subagents for relevant inquiries. \n",
    "\n",
    "\n",
    "A **multi-agent architecture** offers several key benefits:\n",
    "- Specialization & Modularity – Each sub-agent is optimized for a specific task, improving system accuracy \n",
    "- Flexibility – Agents can be quickly added, removed, or modified without affecting the entire system\n",
    "\n",
    "![supervisor](../images/supervisor.png)\n",
    "\n",
    "We will show how we can utilize the pre-built supervisor to quickly create the multi-agent architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a set of instructions for our supervisor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_prompt = \"\"\"You are an expert customer support assistant for a digital music store. \n",
    "You are dedicated to providing exceptional service and ensuring customer queries are answered thoroughly. \n",
    "You have a team of subagents that you can use to help answer queries from customers. \n",
    "Your primary role is to serve as a supervisor/planner for this multi-agent team that helps answer queries from customers. \n",
    "\n",
    "Your team is composed of two subagents that you can use to help answer the customer's request:\n",
    "1. music_catalog_information_subagent: this subagent has access to user's saved music preferences. It can also retrieve information about the digital music store's music \n",
    "catalog (albums, tracks, songs, etc.) from the database. \n",
    "3. invoice_information_subagent: this subagent is able to retrieve information about a customer's past purchases or invoices \n",
    "from the database. \n",
    "\n",
    "Based on the existing steps that have been taken in the messages, your role is to generate the next subagent that needs to be called. \n",
    "This could be one step in an inquiry that needs multiple sub-agent calls. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph_supervisor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph_supervisor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_supervisor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create supervisor workflow\u001b[39;00m\n\u001b[0;32m      4\u001b[0m supervisor_prebuilt_workflow \u001b[38;5;241m=\u001b[39m create_supervisor(\n\u001b[0;32m      5\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[invoice_information_subagent, music_catalog_subagent],\n\u001b[0;32m      6\u001b[0m     output_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_message\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# alternative is full_history\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     state_schema\u001b[38;5;241m=\u001b[39mState\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langgraph_supervisor'"
     ]
    }
   ],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "# Create supervisor workflow\n",
    "supervisor_prebuilt_workflow = create_supervisor(\n",
    "    agents=[invoice_information_subagent, music_catalog_subagent],\n",
    "    output_mode=\"last_message\", # alternative is full_history\n",
    "    model=model,\n",
    "    prompt=(supervisor_prompt), \n",
    "    state_schema=State\n",
    ")\n",
    "\n",
    "supervisor_prebuilt = supervisor_prebuilt_workflow.compile(name=\"music_catalog_subagent\", checkpointer=checkpointer, store=in_memory_store)\n",
    "show_graph(supervisor_prebuilt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "question = \"My customer ID is 1. How much was my most recent purchase? What albums do you have by U2?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = supervisor_prebuilt.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Adding customer verification through human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently invoke our graph with a customer ID as the customer identifier, but realistically, we may not always have access to the customer identity. To solve this, we want to **first verify the customer information** before executing their inquiry with our supervisor agent. \n",
    "\n",
    "In this step, we will be showing a simple implementation of such a node, using **human-in-the-loop** to prompt the customer to provide their account information. \n",
    "\n",
    "![customer-input](../images/human_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will write two nodes: \n",
    "- **verify_info** node that verifies account information \n",
    "- **human_input** node that prompts user to provide additional information \n",
    "\n",
    "ChatModels support attaching a structured data schema to adhere response to. This is useful in scenarios like extracting information or categorizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class UserInput(BaseModel):\n",
    "    \"\"\"Schema for parsing user-provided account information.\"\"\"\n",
    "    identifier: str = Field(description = \"Identifier, which can be a customer ID, email, or phone number.\")\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=UserInput)\n",
    "structured_system_prompt = \"\"\"You are a customer service representative responsible for extracting customer identifier.\\n \n",
    "Only extract the customer's account information from the message history. \n",
    "If they haven't provided the information yet, return an empty string for the file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional \n",
    "\n",
    "# Helper \n",
    "def get_customer_id_from_identifier(identifier: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Retrieve Customer ID using an identifier, which can be a customer ID, email, or phone number.\n",
    "    \n",
    "    Args:\n",
    "        identifier (str): The identifier can be customer ID, email, or phone.\n",
    "    \n",
    "    Returns:\n",
    "        Optional[int]: The CustomerId if found, otherwise None.\n",
    "    \"\"\"\n",
    "    if identifier.isdigit():\n",
    "        return int(identifier)\n",
    "    elif identifier[0] == \"+\":\n",
    "        query = f\"SELECT CustomerId FROM Customer WHERE Phone = '{identifier}';\"\n",
    "        result = db.run(query)\n",
    "        formatted_result = ast.literal_eval(result)\n",
    "        if formatted_result:\n",
    "            return formatted_result[0][0]\n",
    "    elif \"@\" in identifier:\n",
    "        query = f\"SELECT CustomerId FROM Customer WHERE Email = '{identifier}';\"\n",
    "        result = db.run(query)\n",
    "        formatted_result = ast.literal_eval(result)\n",
    "        if formatted_result:\n",
    "            return formatted_result[0][0]\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "\n",
    "def verify_info(state: State, config: RunnableConfig):\n",
    "    \"\"\"Verify the customer's account by parsing their input and matching it with the database.\"\"\"\n",
    "\n",
    "    if state.get(\"customer_id\") is None: \n",
    "        system_instructions = \"\"\"You are a music store agent, where you are trying to verify the customer identity \n",
    "        as the first step of the customer support process. \n",
    "        Only after their account is verified, you would be able to support them on resolving the issue. \n",
    "        In order to verify their identity, one of their customer ID, email, or phone number needs to be provided.\n",
    "        If the customer has not provided their identifier, please ask them for it.\n",
    "        If they have provided the identifier but cannot be found, please ask them to revise it.\"\"\"\n",
    "\n",
    "        user_input = state[\"messages\"][-1] \n",
    "    \n",
    "        # Parse for customer ID\n",
    "        parsed_info = structured_llm.invoke([SystemMessage(content=structured_system_prompt)] + [user_input])\n",
    "    \n",
    "        # Extract details\n",
    "        identifier = parsed_info.identifier\n",
    "    \n",
    "        customer_id = \"\"\n",
    "        # Attempt to find the customer ID\n",
    "        if (identifier):\n",
    "            customer_id = get_customer_id_from_identifier(identifier)\n",
    "    \n",
    "        if customer_id != \"\":\n",
    "            intent_message = SystemMessage(\n",
    "                content= f\"Thank you for providing your information! I was able to verify your account with customer id {customer_id}.\"\n",
    "            )\n",
    "            return {\n",
    "                  \"customer_id\": customer_id,\n",
    "                  \"messages\" : [intent_message]\n",
    "                  }\n",
    "        else:\n",
    "          response = model.invoke([SystemMessage(content=system_instructions)]+state['messages'])\n",
    "          return {\"messages\": [response]}\n",
    "\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our human_input node. We will be prompting the user input through the Interrupt class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "# Node\n",
    "def human_input(state: State, config: RunnableConfig):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    user_input = interrupt(\"Please provide input.\")\n",
    "    return {\"messages\": [user_input]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional_edge\n",
    "def should_interrupt(state: State, config: RunnableConfig):\n",
    "    if state.get(\"customer_id\") is not None:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"interrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes \n",
    "multi_agent_verify = StateGraph(State)\n",
    "multi_agent_verify.add_node(\"verify_info\", verify_info)\n",
    "multi_agent_verify.add_node(\"human_input\", human_input)\n",
    "multi_agent_verify.add_node(\"supervisor\", supervisor_prebuilt)\n",
    "\n",
    "multi_agent_verify.add_edge(START, \"verify_info\")\n",
    "multi_agent_verify.add_conditional_edges(\n",
    "    \"verify_info\",\n",
    "    should_interrupt,\n",
    "    {\n",
    "        \"continue\": \"supervisor\",\n",
    "        \"interrupt\": \"human_input\",\n",
    "    },\n",
    ")\n",
    "multi_agent_verify.add_edge(\"human_input\", \"verify_info\")\n",
    "multi_agent_verify.add_edge(\"supervisor\", END)\n",
    "multi_agent_verify_graph = multi_agent_verify.compile(name=\"multi_agent_verify\", checkpointer=checkpointer, store=in_memory_store)\n",
    "show_graph(multi_agent_verify_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "question = \"How much was my most recent purchase?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = multi_agent_verify_graph.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Resume from interrupt \n",
    "question = \"My phone number is +55 (12) 3923-5555.\"\n",
    "result = multi_agent_verify_graph.invoke(Command(resume=question), config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if I ask a follow-up question in the same thread, our agent state stores our customer_id, not needing to verify again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"What albums do you have by the Rolling Stones?\"\n",
    "result = multi_agent_verify_graph.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Adding Long-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created an agent workflow that includes verification and execution, let's take it a step further. \n",
    "\n",
    "**Long term memory** lets you store and recall information between conversations. We have already initialized a long term memory store. \n",
    "\n",
    "\n",
    "![memory](../images/memory.png)\n",
    "\n",
    "In this step, we will add 2 nodes: \n",
    "- **load_memory** node that loads from the long term memory store\n",
    "- **create_memory** node that saves any music interests that the customer has shared about themselves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# helper function to structure memory \n",
    "def format_user_memory(user_data):\n",
    "    \"\"\"Formats music preferences from users, if available.\"\"\"\n",
    "    profile = user_data['memory']\n",
    "    result = \"\"\n",
    "    if hasattr(profile, 'music_preferences') and profile.music_preferences:\n",
    "        result += f\"Music Preferences: {', '.join(profile.music_preferences)}\"\n",
    "    return result.strip()\n",
    "\n",
    "# Node\n",
    "def load_memory(state: State, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Loads music preferences from users, if available.\"\"\"\n",
    "    \n",
    "    user_id = state[\"customer_id\"]\n",
    "    namespace = (\"memory_profile\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "    formatted_memory = \"\"\n",
    "    if existing_memory and existing_memory.value:\n",
    "        formatted_memory = format_user_memory(existing_memory.value)\n",
    "\n",
    "    return {\"loaded_memory\" : formatted_memory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile structure for creating memory\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    customer_id: str = Field(\n",
    "        description=\"The customer ID of the customer\"\n",
    "    )\n",
    "    music_preferences: List[str] = Field(\n",
    "        description=\"The music preferences of the customer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_memory_prompt = \"\"\"You are an expert analyst that is observing a conversation that has taken place between a customer and a customer support assistant. The customer support assistant works for a digital music store, and has utilized a multi-agent team to answer the customer's request. \n",
    "You are tasked with analyzing the conversation that has taken place between the customer and the customer support assistant, and updating the memory profile associated with the customer. The memory profile may be empty. If it's empty, you should create a new memory profile for the customer.\n",
    "\n",
    "You specifically care about saving any music interest the customer has shared about themselves, particularly their music preferences to their memory profile.\n",
    "\n",
    "To help you with this task, I have attached the conversation that has taken place between the customer and the customer support assistant below, as well as the existing memory profile associated with the customer that you should either update or create. \n",
    "\n",
    "The customer's memory profile should have the following fields:\n",
    "- customer_id: the customer ID of the customer\n",
    "- music_preferences: the music preferences of the customer\n",
    "\n",
    "These are the fields you should keep track of and update in the memory profile. If there has been no new information shared by the customer, you should not update the memory profile. It is completely okay if you do not have new information to update the memory profile with. In that case, just leave the values as they are.\n",
    "\n",
    "*IMPORTANT INFORMATION BELOW*\n",
    "\n",
    "The conversation between the customer and the customer support assistant that you should analyze is as follows:\n",
    "{conversation}\n",
    "\n",
    "The existing memory profile associated with the customer that you should either update or create based on the conversation is as follows:\n",
    "{memory_profile}\n",
    "\n",
    "Ensure your response is an object that has the following fields:\n",
    "- customer_id: the customer ID of the customer\n",
    "- music_preferences: the music preferences of the customer\n",
    "\n",
    "For each key in the object, if there is no new information, do not update the value, just keep the value that is already there. If there is new information, update the value. \n",
    "\n",
    "Take a deep breath and think carefully before responding.\n",
    "\"\"\"\n",
    "\n",
    "# Node\n",
    "def create_memory(state: State, config: RunnableConfig, store: BaseStore):\n",
    "    user_id = str(state[\"customer_id\"])\n",
    "    namespace = (\"memory_profile\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "    if existing_memory and existing_memory.value:\n",
    "        existing_memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Music Preferences: {', '.join(existing_memory_dict.get('music_preferences', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = \"\"\n",
    "    formatted_system_message = SystemMessage(content=create_memory_prompt.format(conversation=state[\"messages\"], memory_profile=formatted_memory))\n",
    "    updated_memory = model.with_structured_output(UserProfile).invoke([formatted_system_message])\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, {\"memory\": updated_memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_agent_final = StateGraph(State)\n",
    "multi_agent_final.add_node(\"verify_info\", verify_info)\n",
    "multi_agent_final.add_node(\"human_input\", human_input)\n",
    "multi_agent_final.add_node(\"load_memory\", load_memory)\n",
    "multi_agent_final.add_node(\"supervisor\", supervisor_prebuilt)\n",
    "multi_agent_final.add_node(\"create_memory\", create_memory)\n",
    "\n",
    "multi_agent_final.add_edge(START, \"verify_info\")\n",
    "multi_agent_final.add_conditional_edges(\n",
    "    \"verify_info\",\n",
    "    should_interrupt,\n",
    "    {\n",
    "        \"continue\": \"load_memory\",\n",
    "        \"interrupt\": \"human_input\",\n",
    "    },\n",
    ")\n",
    "multi_agent_final.add_edge(\"human_input\", \"verify_info\")\n",
    "multi_agent_final.add_edge(\"load_memory\", \"supervisor\")\n",
    "multi_agent_final.add_edge(\"supervisor\", \"create_memory\")\n",
    "multi_agent_final.add_edge(\"create_memory\", END)\n",
    "multi_agent_final_graph = multi_agent_final.compile(name=\"multi_agent_verify\", checkpointer=checkpointer, store=in_memory_store)\n",
    "show_graph(multi_agent_final_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "\n",
    "question = \"My phone number is +55 (12) 3923-5555. How much was my most recent purchase? What albums do you have by the Rolling Stones?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = multi_agent_final_graph.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace = (\"memory_profile\", user_id)\n",
    "memory = in_memory_store.get(namespace, \"user_memory\").value\n",
    "\n",
    "saved_music_preferences = memory.get(\"memory\").music_preferences\n",
    "\n",
    "print(saved_music_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (Optional) Build a Swarm Multi-Agent Graph\n",
    "\n",
    "### Swarm Architecture\n",
    "\n",
    "![swarm](../images/swarm.png) \n",
    "\n",
    "There is another popular framework for building multi-agent graphs called Swarm. At LangChain, we built a [lightweight library](https://github.com/langchain-ai/langgraph-swarm-py) to help make Swarm agents very easily! Swarm agents are designed for collaborative problem-solving where multiple specialized agents work together, without a central coordinator.\n",
    "\n",
    "### Swarm vs Supervisor\n",
    "\n",
    "![swarm_vs_supervisor](../images/supervisor_vs_swarm.png)\n",
    "\n",
    "Swarm architecture differs from supervisor-based approaches by emphasizing decentralized collaboration rather than hierarchical control. In a supervisor architecture, a central agent coordinates the workflow, delegates tasks, and makes decisions about which subagents to call. This creates a clear hierarchy where the supervisor has authority over specialized agents.\n",
    "\n",
    "The supervisor approach offers more control and predictability, while swarm architectures can be more adaptable and resilient to individual agent failures. Your choice between these approaches depends on whether your use case benefits more from centralized oversight or emergent collaboration.\n",
    "\n",
    "For more information there is a great video by Lance from our team at Langchain breaking down Supervisor vs Swarm: [Multi-agent swarms with LangGraph](https://www.youtube.com/watch?v=JeyDrn1dSUQ)\n",
    "\n",
    "Let's create swarm agents!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "\n",
    "# Create our handoff tools between agents\n",
    "\n",
    "transfer_to_invoice_agent_handoff_tool = create_handoff_tool(\n",
    "    agent_name = \"invoice_information_agent_with_handoff\",\n",
    "    description = \"Transfer user to the invoice information agent that can help with invoice information\"\n",
    ")\n",
    "\n",
    "transfer_to_music_catalog_agent_handoff_tool = create_handoff_tool(\n",
    "    agent_name = \"music_catalog_agent_with_handoff\", \n",
    "    description = \"Transfer user to the music catalog agent that can help with music searches and music catalog information\"\n",
    ")\n",
    "\n",
    "# Recreate our agents with the handoff tools\n",
    "\n",
    "# First let's create our tools with handoff tools added to them\n",
    "invoice_tools_with_handoff = [transfer_to_music_catalog_agent_handoff_tool] + invoice_tools\n",
    "music_tools_with_handoff = [transfer_to_invoice_agent_handoff_tool] + music_tools\n",
    "\n",
    "invoice_information_agent_with_handoff = create_react_agent(\n",
    "    model,\n",
    "    invoice_tools_with_handoff,\n",
    "    prompt = invoice_subagent_prompt,\n",
    "    name = \"invoice_information_agent_with_handoff\"\n",
    ")\n",
    "\n",
    "# pull music catalog agent prompt from the previous custom react agent implementation\n",
    "\n",
    "\n",
    "music_catalog_agent_with_handoff = create_react_agent(\n",
    "    model,\n",
    "    music_tools_with_handoff,\n",
    "    prompt = generate_music_assistant_prompt(),\n",
    "    name = \"music_catalog_agent_with_handoff\"\n",
    ")\n",
    "\n",
    "\n",
    "swarm_workflow = create_swarm(\n",
    "    agents = [invoice_information_agent_with_handoff, music_catalog_agent_with_handoff],\n",
    "    default_active_agent = \"invoice_information_agent_with_handoff\",\n",
    ")\n",
    "\n",
    "# Compile with checkpointer/store\n",
    "swarm_agents = swarm_workflow.compile(\n",
    "    checkpointer = checkpointer,\n",
    "    store = in_memory_store\n",
    ")\n",
    "\n",
    "show_graph(swarm_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "question = \"Do you have any albums by the Rolling Stones?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Invoke the swarm agents. The default active agent will hand off to our music catalog agent instead of trying to solve the problem itself\n",
    "result = swarm_agents.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations\n",
    "\n",
    "**Evaluations** are a quantitative way to measure performance of agents, which is important beacause LLMs don't always behave precitably — small changes in prompts, models, or inputs can significantly impact results. Evaluations provide a structured way to identify failures, compare changes across different versions of your applicaiton, and build more reliable AI applications.\n",
    "\n",
    "Evaluations are made up of three components:\n",
    "\n",
    "1. A **dataset test** inputs and expected outputs.\n",
    "2. An **application or target function** that defines what you are evaluating, taking in inputs and returning the application output\n",
    "3. **Evaluators** that score your target function's outputs.\n",
    "\n",
    "![Evaluation](../images/evals-conceptual.png) \n",
    "\n",
    "There are many ways you can evaluate an agent. Today, we will cover the three common types of agent evaluations:\n",
    "\n",
    "1. **Final Response**: Evaluate the agent's final response.\n",
    "2. **Single step**: Evaluate any agent step in isolation (e.g., whether it selects the appropriate tool).\n",
    "3. **Trajectory**: Evaluate whether the agent took the expected path (e.g., of tool calls) to arrive at the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating The Final Response\n",
    "\n",
    "One way to evaluate an agent is to assess its overall performance on a task. This basically involves treating the agent as a black box and simply evaluating whether or not it gets the job done.\n",
    "- Input: User input \n",
    "- Output: The agent's final response.\n",
    "\n",
    "\n",
    "![final-response](../images/final-response.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Create a dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"My name is Aaron Mitchell. My number associated with my account is +1 (204) 452-6452. I am trying to find the invoice number for my most recent song purchase. Could you help me with it?\",\n",
    "        \"response\": \"The Invoice ID of your most recent purchase was 342.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I'd like a refund.\",\n",
    "        \"response\": \"I need additional information to help you with the refund. Could you please provide your customer identifier so that we can fetch your purchase history?\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who recorded Wish You Were Here again?\",\n",
    "        \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n",
    "    },\n",
    "    { \n",
    "        \"question\": \"What albums do you have by Coldplay?\",\n",
    "        \"response\": \"There are no Coldplay albums available in our catalog at the moment.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_name = \"LangGraph 101 Multi-Agent: Final Response\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs=[{\"question\": ex[\"question\"]} for ex in examples],\n",
    "        outputs=[{\"response\": ex[\"response\"]} for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Application Logic to be Evaluated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define how to run our graph. Note that here we must continue past the interrupt() by supplying a Command(resume=\"\") to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.types import Command\n",
    "\n",
    "graph = multi_agent_final_graph\n",
    "\n",
    "async def run_graph(inputs: dict):\n",
    "    \"\"\"Run graph and track the final response.\"\"\"\n",
    "    # Creating configuration \n",
    "    thread_id = uuid.uuid4()\n",
    "    configuration = {\"thread_id\": thread_id, \"user_id\" : \"10\"}\n",
    "\n",
    "    # Invoke graph until interrupt \n",
    "    result = await graph.ainvoke({\"messages\": [\n",
    "        { \"role\": \"user\", \"content\": inputs['question']}]}, config = configuration)\n",
    "    # Proceed from human-in-the-loop \n",
    "    result = await graph.ainvoke(Command(resume=\"My customer ID is 10\"), config={\"thread_id\": thread_id, \"user_id\" : \"10\"})\n",
    "    \n",
    "    return {\"response\": result['messages'][-1].content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pre-built evaluators from the `openevals` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.llm import create_llm_as_judge\n",
    "from openevals.prompts import CORRECTNESS_PROMPT\n",
    "\n",
    "# Using Open Eval pre-built \n",
    "correctness_evaluator = create_llm_as_judge(\n",
    "    prompt=CORRECTNESS_PROMPT,\n",
    "    feedback_key=\"correctness\",\n",
    "    judge=model,\n",
    ")\n",
    "print(CORRECTNESS_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define our own evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom definition of LLM-as-judge instructions\n",
    "grader_instructions = \"\"\"You are a teacher grading a quiz.\n",
    "\n",
    "You will be given a QUESTION, the GROUND TRUTH (correct) RESPONSE, and the STUDENT RESPONSE.\n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "(1) Grade the student responses based ONLY on their factual accuracy relative to the ground truth answer.\n",
    "(2) Ensure that the student response does not contain any conflicting statements.\n",
    "(3) It is OK if the student response contains more information than the ground truth response, as long as it is factually accurate relative to the ground truth response.\n",
    "\n",
    "Correctness:\n",
    "True means that the student's response meets all of the criteria.\n",
    "False means that the student's response does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct.\"\"\"\n",
    "\n",
    "# LLM-as-judge output schema\n",
    "class Grade(TypedDict):\n",
    "    \"\"\"Compare the expected and actual answers and grade the actual answer.\"\"\"\n",
    "    reasoning: Annotated[str, ..., \"Explain your reasoning for whether the actual response is correct or not.\"]\n",
    "    is_correct: Annotated[bool, ..., \"True if the student response is mostly or exactly correct, otherwise False.\"]\n",
    "\n",
    "# Judge LLM\n",
    "grader_llm = model.with_structured_output(Grade, method=\"json_schema\", strict=True)\n",
    "\n",
    "# Evaluator function\n",
    "async def final_answer_correct(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"Evaluate if the final response is equivalent to reference response.\"\"\"\n",
    "    # Note that we assume the outputs has a 'response' dictionary. We'll need to make sure\n",
    "    # that the target function we define includes this key.\n",
    "    user = f\"\"\"QUESTION: {inputs['question']}\n",
    "    GROUND TRUTH RESPONSE: {reference_outputs['response']}\n",
    "    STUDENT RESPONSE: {outputs['response']}\"\"\"\n",
    "\n",
    "    grade = await grader_llm.ainvoke([{\"role\": \"system\", \"content\": grader_instructions}, {\"role\": \"user\", \"content\": user}])\n",
    "    return grade[\"is_correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation job and results\n",
    "experiment_results = await client.aevaluate(\n",
    "    run_graph,\n",
    "    data=dataset_name,\n",
    "    evaluators=[final_answer_correct, correctness_evaluator],\n",
    "    experiment_prefix=\"agent-o3mini-e2e\",\n",
    "    num_repetitions=1,\n",
    "    max_concurrency=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Single Step of the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents generally perform multiple actions. While it is useful to evaluate them end-to-end, it can also be useful to evaluate these individual actions, similar to the concept of unit testing in software development. This generally involves evaluating a single step of the agent - the LLM call where it decides what to do.\n",
    "\n",
    "- Input: Input to a single step \n",
    "- Output: Output of that step, which is usually the LLM response\n",
    "![single-step](../images/single-step.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a Dataset for this Single Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"messages\": \"My customer ID is 1. What's my most recent purchase? and What albums does the catalog have by U2?\", \n",
    "        \"route\": 'transfer_to_invoice_information_subagent'\n",
    "    },\n",
    "    {\n",
    "        \"messages\": \"What songs do you have by U2?\", \n",
    "        \"route\": 'transfer_to_music_catalog_subagent'\n",
    "    },\n",
    "    {\n",
    "        \"messages\": \"My name is Aaron Mitchell. My number associated with my account is +1 (204) 452-6452. I am trying to find the invoice number for my most recent song purchase. Could you help me with it?\", \n",
    "        \"route\": 'transfer_to_invoice_information_subagent'\n",
    "    },\n",
    "    {\n",
    "        \"messages\": \"Who recorded Wish You Were Here again? What other albums by them do you have?\", \n",
    "        \"route\": 'transfer_to_music_catalog_subagent'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name = \"LangGraph 101 Multi-Agent: Single-Step\"\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs = [{\"messages\": ex[\"messages\"]} for ex in examples],\n",
    "        outputs = [{\"route\": ex[\"route\"]} for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the Application Logic to Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to evaluate the supervisor routing step, so let's add a breakpoint right after the supervisor step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_supervisor_routing(inputs: dict):\n",
    "    result = await supervisor_prebuilt.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=inputs['messages'])]},\n",
    "        interrupt_before=[\"music_catalog_subagent\", \"invoice_information_subagent\"],\n",
    "        config={\"thread_id\": uuid.uuid4(), \"user_id\" : \"10\"}\n",
    "    )\n",
    "    return {\"route\": result[\"messages\"][-1].name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"Check if the agent chose the correct route.\"\"\"\n",
    "    return outputs['route'] == reference_outputs[\"route\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = await client.aevaluate(\n",
    "    run_supervisor_routing,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correct],\n",
    "    experiment_prefix=\"agent-o3mini-singlestep\",\n",
    "    max_concurrency=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Trajectory of the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating an agent's trajectory involves evaluating all the steps an agent took. The evaluator here is some function over the steps taken. Examples of evaluators include an exact match for each tool name in the sequence or the number of \"incorrect\" steps taken.\n",
    "\n",
    "- Input: User input to the overall agent \n",
    "- Output: A list of steps taken.\n",
    "![trajectory](../images/trajectory.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"My customer ID is 1. What's my most recent purchase? and What albums does the catalog have by U2?\",\n",
    "        \"trajectory\": [\"verify_info\", \"load_memory\", \"supervisor\", \"create_memory\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What songs do you have by U2?\",\n",
    "        \"trajectory\": [\"verify_info\", \"human_input\", \"human_input\", \"verify_info\", \"human_input\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"My name is Aaron Mitchell. My number associated with my account is +1 (204) 452-6452. I am trying to find the invoice number for my most recent song purchase. Could you help me with it?\",\n",
    "        \"trajectory\": [\"verify_info\", \"load_memory\", \"supervisor\", \"create_memory\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who recorded Wish You Were Here again? What other albums by them do you have?\",\n",
    "        \"trajectory\": [\"verify_info\", \"human_input\", \"human_input\", \"verify_info\", \"human_input\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_name = \"LangGraph 101 Multi-Agent: Trajectory Eval\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs=[{\"question\": ex[\"question\"]} for ex in examples],\n",
    "        outputs=[{\"trajectory\": ex[\"trajectory\"]} for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the Application Logic to Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = multi_agent_final_graph\n",
    "\n",
    "async def run_graph(inputs: dict) -> dict:\n",
    "    \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n",
    "    trajectory = []\n",
    "    thread_id = uuid.uuid4()\n",
    "    configuration = {\"thread_id\": thread_id, \"user_id\" : \"10\"}\n",
    "\n",
    "    # Run until interrupt \n",
    "    async for chunk in graph.astream({\"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": inputs['question'],\n",
    "            }\n",
    "        ]}, config = configuration, stream_mode=\"debug\"):\n",
    "        if chunk['type'] == 'task':\n",
    "            trajectory.append(chunk['payload']['name'])\n",
    "\n",
    "    # Resume from interrupt\n",
    "    async for chunk in graph.astream(Command(resume=\"\"), config = configuration, stream_mode=\"debug\"):\n",
    "        if chunk['type'] == 'task':\n",
    "            trajectory.append(chunk['payload']['name'])\n",
    "    return {\"trajectory\": trajectory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exact_match(outputs: dict, reference_outputs: dict):\n",
    "    \"\"\"Evaluate whether the trajectory exactly matches the expected output\"\"\"\n",
    "    return {\n",
    "        \"key\": \"exact_match\", \n",
    "        \"score\": outputs[\"trajectory\"] == reference_outputs[\"trajectory\"]\n",
    "    }\n",
    "\n",
    "def evaluate_extra_steps(outputs: dict, reference_outputs: dict) -> dict:\n",
    "    \"\"\"Evaluate the number of unmatched steps in the agent's output.\"\"\"\n",
    "    i = j = 0\n",
    "    unmatched_steps = 0\n",
    "\n",
    "    while i < len(reference_outputs['trajectory']) and j < len(outputs['trajectory']):\n",
    "        if reference_outputs['trajectory'][i] == outputs['trajectory'][j]:\n",
    "            i += 1  # Match found, move to the next step in reference trajectory\n",
    "        else:\n",
    "            unmatched_steps += 1  # Step is not part of the reference trajectory\n",
    "        j += 1  # Always move to the next step in outputs trajectory\n",
    "\n",
    "    # Count remaining unmatched steps in outputs beyond the comparison loop\n",
    "    unmatched_steps += len(outputs['trajectory']) - j\n",
    "\n",
    "    return {\n",
    "        \"key\": \"unmatched_steps\",\n",
    "        \"score\": unmatched_steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = await client.aevaluate(\n",
    "    run_graph,\n",
    "    data=dataset_name,\n",
    "    evaluators=[evaluate_extra_steps, evaluate_exact_match],\n",
    "    experiment_prefix=\"agent-o3mini-trajectory\",\n",
    "    num_repetitions=1,\n",
    "    max_concurrency=4,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
